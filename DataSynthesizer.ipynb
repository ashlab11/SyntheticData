{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from synthpop import Synthpop\n",
    "from DataSynthesizer.DataDescriber import DataDescriber\n",
    "from DataSynthesizer.DataGenerator import DataGenerator\n",
    "from DataSynthesizer.ModelInspector import ModelInspector\n",
    "from DataSynthesizer.lib.utils import read_json_file, display_bayesian_network\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing = pd.read_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING DATA\n",
    "#Here, we merely create the datasets. We are not synthesizing anything or imputing anything yet.\n",
    "for sim in range(10):\n",
    "    #Original Dataset\n",
    "    no_missing_train, no_missing_test = train_test_split(housing, test_size=0.2)\n",
    "    no_missing_train.to_csv(f'Datasets/housing_original_train_{sim}.csv', index=False)\n",
    "    no_missing_test.to_csv(f'Datasets/housing_original_test_{sim}.csv', index=False)\n",
    "    \n",
    "    #MAR \n",
    "    #People with a guest room and area > 5000 will not report their number of bedrooms, or whether they have parking, or aircon\n",
    "    #People without aircon or hotwater will not report how many stories\n",
    "    mar_train = no_missing_train.copy()\n",
    "    mar_train.loc[(mar_train['guestroom'] == \"yes\") & (mar_train['area'] > 5000), ['bedrooms', 'parking']] = np.nan\n",
    "    mar_train.loc[(mar_train['hotwaterheating'] == \"no\") & (mar_train['airconditioning'] == \"no\"), 'stories'] = np.nan\n",
    "    mar_test = no_missing_test.copy()\n",
    "    mar_test.loc[(mar_test['guestroom'] == \"yes\") & (mar_test['area'] > 5000), ['bedrooms', 'parking']] = np.nan\n",
    "    mar_test.loc[(mar_test['hotwaterheating'] == \"no\") & (mar_test['airconditioning'] == \"no\"), 'stories'] = np.nan\n",
    "\n",
    "    \n",
    "    mar_train.to_csv('Datasets/housing_mar_train_'+str(sim)+'.csv', index=False)\n",
    "    mar_test.to_csv('Datasets/housing_mar_test_'+str(sim)+'.csv', index=False)\n",
    "    \n",
    "    #MNAR\n",
    "    #People with an area greater than 6000 sqft and more than two bedrooms will not report their area\n",
    "    #People with >2 stories and a basement will not report their guestroom\n",
    "    mnar_train = no_missing_train.copy()\n",
    "    mnar_train.loc[(mnar_train['parking'] >= 2) & (mnar_train['bedrooms'] > 2), ['bedrooms', 'parking']] = np.nan\n",
    "    mnar_train.loc[(mnar_train['stories'] > 2) & (mnar_train['basement'] == \"yes\"), 'stories'] = np.nan\n",
    "    mnar_test = no_missing_test.copy()\n",
    "    mnar_test.loc[(mnar_test['parking'] >= 2) & (mnar_test['bedrooms'] > 2), ['bedrooms', 'parking']] = np.nan\n",
    "    mnar_test.loc[(mnar_test['stories'] > 2) & (mnar_test['basement'] == \"yes\"), 'stories'] = np.nan\n",
    "    \n",
    "    mnar_train.to_csv(f'Datasets/housing_mnar_train_{sim}.csv', index=False)\n",
    "    mnar_test.to_csv(f'Datasets/housing_mnar_test_{sim}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Constructing Bayesian Network (BN) ================\n",
      "Adding ROOT guestroom\n",
      "Adding attribute price\n",
      "Adding attribute area\n",
      "Adding attribute stories\n",
      "Adding attribute bedrooms\n",
      "Adding attribute furnishingstatus\n",
      "Adding attribute parking\n",
      "Adding attribute bathrooms\n",
      "Adding attribute basement\n",
      "Adding attribute airconditioning\n",
      "Adding attribute prefarea\n",
      "Adding attribute mainroad\n",
      "Adding attribute hotwaterheating\n",
      "========================== BN constructed ==========================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m describer\u001b[38;5;241m.\u001b[39msave_dataset_description_to_file(description_json_name)\n\u001b[1;32m     22\u001b[0m generator \u001b[38;5;241m=\u001b[39m DataGenerator()\n\u001b[0;32m---> 23\u001b[0m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_dataset_in_correlated_attribute_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription_json_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m new_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatasets/synthesizer\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mversion\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_train_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(sim)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     26\u001b[0m generator\u001b[38;5;241m.\u001b[39msave_synthetic_data(new_file_name)\n",
      "File \u001b[0;32m~/miniconda3/envs/SyntheticData/lib/python3.12/site-packages/DataSynthesizer/DataGenerator.py:65\u001b[0m, in \u001b[0;36mDataGenerator.generate_dataset_in_correlated_attribute_mode\u001b[0;34m(self, n, description_file, seed)\u001b[0m\n\u001b[1;32m     63\u001b[0m all_attributes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_attributes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     64\u001b[0m candidate_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcandidate_keys\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoded_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataGenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_encoded_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynthetic_dataset \u001b[38;5;241m=\u001b[39m DataFrame(columns\u001b[38;5;241m=\u001b[39mall_attributes)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m all_attributes:\n",
      "File \u001b[0;32m~/miniconda3/envs/SyntheticData/lib/python3.12/site-packages/DataSynthesizer/DataGenerator.py:107\u001b[0m, in \u001b[0;36mDataGenerator.generate_encoded_dataset\u001b[0;34m(n, description)\u001b[0m\n\u001b[1;32m    103\u001b[0m     filter_condition \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(encoded_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)&\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m filter_condition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(filter_condition[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 107\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[43mencoded_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilter_condition\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size:\n\u001b[1;32m    109\u001b[0m     encoded_df\u001b[38;5;241m.\u001b[39mloc[filter_condition, child] \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(dist), size\u001b[38;5;241m=\u001b[39msize, p\u001b[38;5;241m=\u001b[39mdist)\n",
      "File \u001b[0;32m~/miniconda3/envs/SyntheticData/lib/python3.12/site-packages/pandas/core/frame.py:4081\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4079\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m   4080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 4081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4083\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[1;32m   4084\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[1;32m   4085\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[0;32m~/miniconda3/envs/SyntheticData/lib/python3.12/site-packages/pandas/core/frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   4142\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 4143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/SyntheticData/lib/python3.12/site-packages/pandas/core/generic.py:4150\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4139\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   4140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   4141\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   4143\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4148\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   4149\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4150\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4151\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   4152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m~/miniconda3/envs/SyntheticData/lib/python3.12/site-packages/pandas/core/generic.py:4130\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4125\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[1;32m   4126\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4127\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4128\u001b[0m     )\n\u001b[0;32m-> 4130\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4132\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4136\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4137\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/SyntheticData/lib/python3.12/site-packages/pandas/core/internals/managers.py:891\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;66;03m# Caller is responsible for ensuring indexer annotation is accurate\u001b[39;00m\n\u001b[1;32m    890\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[0;32m--> 891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[1;32m    895\u001b[0m     new_axis\u001b[38;5;241m=\u001b[39mnew_labels,\n\u001b[1;32m    896\u001b[0m     indexer\u001b[38;5;241m=\u001b[39mindexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    899\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    900\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/SyntheticData/lib/python3.12/site-packages/pandas/core/indexers/utils.py:275\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n\u001b[1;32m    274\u001b[0m mask \u001b[38;5;241m=\u001b[39m indices \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    276\u001b[0m     indices \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    277\u001b[0m     indices[mask] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m n\n",
      "File \u001b[0;32m~/miniconda3/envs/SyntheticData/lib/python3.12/site-packages/numpy/core/_methods.py:55\u001b[0m, in \u001b[0;36m_any\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prod\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     52\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_prod(a, axis, dtype, out, keepdims, initial, where)\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_any\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "threshold_value = 10\n",
    "categorical_values = {'price': False,'mainroad': True, \n",
    "                      'guestroom': True, \n",
    "                      'basement': True, \n",
    "                      'hotwaterheating': True, \n",
    "                      'airconditioning': True, \n",
    "                      'prefarea': True, \n",
    "                      'furnishingstatus': True}\n",
    "epsilon = 0\n",
    "versions = ['original', 'mar', 'mnar']\n",
    "datasets = range(1)\n",
    "for version in versions:\n",
    "    for sim in datasets:\n",
    "        dataset = pd.read_csv(f'Datasets/housing_{version}_train_{sim}.csv')\n",
    "        rows = len(dataset)\n",
    "        describer = DataDescriber(category_threshold=threshold_value)\n",
    "        describer.describe_dataset_in_correlated_attribute_mode(dataset_file=f'Datasets/housing_{version}_train_{sim}.csv', \n",
    "                                                                epsilon=epsilon,\n",
    "                                                                attribute_to_is_categorical=categorical_values)\n",
    "        description_json_name = 'Datasets/housing_'+version+'_description_'+str(sim)+'.json'\n",
    "        describer.save_dataset_description_to_file(description_json_name)\n",
    "        generator = DataGenerator()\n",
    "        \n",
    "        generator.generate_dataset_in_correlated_attribute_mode(rows, description_json_name)\n",
    "        \n",
    "        new_file_name = f'Datasets/housing_synthesizer{version}_train_{sim}.csv'\n",
    "        generator.save_synthetic_data(new_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = DataGenerator()\n",
    "generator.generate_dataset_in_correlated_attribute_mode(rows, \"housing_description.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save_synthetic_data('synthetic_housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method generate_dataset_in_correlated_attribute_mode in module DataSynthesizer.DataGenerator:\n",
      "\n",
      "generate_dataset_in_correlated_attribute_mode(n, description_file, seed=0) method of DataSynthesizer.DataGenerator.DataGenerator instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DataGenerator().generate_dataset_in_correlated_attribute_mode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
